\documentclass{llncs}

%\usepackage{makeidx}  % allows for indexgeneration
\usepackage{graphicx}

\begin{document}

\title{Mailing lists meet the Semantic Web}

\titlerunning{Mailing lists meet the Semantic Web}

\author{
Sergio Fern\'andez\inst{1} 
\and
Diego Berrueta\inst{1} 
\and
Jose E. Labra\inst{2}
}

\authorrunning{Sergio Fern\'andez et al.}

\tocauthor{Sergio Fern\'andez, Diego Berrueta, Jose E. Labra} 

\institute{%
Fundaci\'on CTIC, \\
Gij\'on, Asturias, Spain,\\
\email{\{sergio.fernandez,diego.berrueta\}@fundacionctic.org}
\and
Universidad de Oviedo,\\
Computer Science Department,\\
Oviedo, Asturias, Spain,\\
\email{labra@uniovi.es}\\
}

\date{18 February 2007}

\maketitle

\begin{abstract}

Mailing list archives (i.e., the messages posted up-to-now) are often 
published on the web and indexed by conventional search engines. They 
store a vast knowledge capital. However, the ability to auto-matically 
recognize and process the information is mostly lost at publishing time. 
As a result, the current mailing list archives are hard to query and have 
a limited use. This paper describes how SWAML uses Semantic Web technologies 
in order to avoid the information loss and to allow new applications 
to exploit this information in a more convenient way.

\end{abstract}

\section{Introduction}

Electronic mail (e-mail) remains one of the most
popular applications of the Internet. Besides direct messaging
between individuals, mailing lists exist as private or public
forums for information exchange in communities with shared interests.
Mailing list archives are compilations of the previously posted
messages that are often converted into static HTML for its
publication on the web. They represent a significative portion of
the contents that are indexed by the web search engines, and they
capture an impressive body of knowledge that, however, is difficult
to locate and browse.

The root of these problems can be traced back to the translation
procedure that is run to transform the e-mail messages into static
HTML pages. This task is fulfilled by scripts that create an
static HTML page for each message in the archive, in addition to
some indexes (by date, by author, by thread), often splitted by
date intervals to avoid excessive growth. On the one hand, this 
fixed structure reduces the flexibility when the user browses the
mailing list archives from his web browser. On the other hand, some 
of the metadata that was associated to each e-mail message is lost
when it is rendered as HTML for presentational purpouses.

We propose to use an ontology and RDF (Resource Description Framework
\cite{RDF}) to enable the publishing of the mailing list archives into 
the (Semantic) web, while retaining the metadata that were present in 
the messages. The rest of the paper is organized as follows: 
Section~\ref{sec:SIOC} introduces the SIOC ontology and our extensions 
to it, and then our software applications are described in 
Section~\ref{sec:tools}. We close the paper with the conclusions and 
a discussion about our future plans in Section~\ref{sec:conclusions}.

\section{\label{sec:SIOC}SIOC}

An ontology to capture the metadata of a discussion forum, such as
a mailing list, was clearly recognized as the first milestone to
fulfil the purpose of the project. Fortunately, DERI Galway has 
developed SIOC\footnote{\url{http://sioc-project.org/}} (Semantically-Interlinked 
Online Communities), an ontology that provides methods for interconnecting 
discussion methods such as blogs, forums and mailing 
lists~\cite{Breslin2006}\cite{Breslin2005}. Indeed, SIOC has a wider 
scope than just mailing lists, and groups all kinds of online discussion 
primitives on a generic \textsf{sioc:Forum} concept. Each forum represents 
an online community of people that share a common interest. The goal 
of SIOC is to interconnect these online communities. Other key concepts 
of the ontology are \textsf{sioc:User} and \textsf{sioc:Post}, which 
model respectively the members of the communities and the content they 
produce, respectively.

%FIXME: very ugly 
%\begin{figure}[ht]
% \centering
% \includegraphics[bb=0 0 349 161]{images/sioc-classes.png}
% \caption{SIOC classes and relationships involved in SWAML}
%\end{figure}

The SIOC ontology is designed to express the information contained
both explicitly  and implicitly in internet discussion methods. Several 
software applications, usually deployed as plugins, are already available 
to export SIOC data from some popular blogging platforms and content 
management systems. The effort, however, is focused on web-based communities 
(weblogs, webforums), while little has been done so far to extend the coverage 
to legacy non-web communities, such us mailing lists and Usenet groups.

SIOC is specified using OWL, and their instances are expressed
in RDF. Therefore, they can be easily linked to other ontologies.
The obvious choice here is FOAF~\cite{FOAF}, which provides more
powerful means to describe the personal data of the members of
a community.

\subsection{Extension to SIOC}

SIOC was quickly identified as an almost perfect match for our
purpose. Each mailing list is an instance of \textsf{sioc:Forum},
messages sent to the list become instances of \textsf{sioc:Post}
(as well as their replies), and the people subscribed to the
list are \textsf{sioc:User}s. The Dublin Core~\cite{DublinCore}
vocabulary is used to capture metadata such as the message
date or title.

However, additional object properties were required
in order to capture the sequence of messages published in a
mailing list. Thus, we extended the SIOC ontology with two
properties\footnote{These properties are defined in a separate
namespace, \url{http://swaml.berlios.de/ns/0.2\#}}:
\textsf{previousByDate} and \textsf{nextByDate}. Both properties
are defined with \textsf{sioc:Post} as their domain and range.

\section{\label{sec:tools}Software tools}

In the SWAML project some software tools has been developed using the Python 
programming language, mainly three:

\begin{itemize}
 \item SWAML, the core process that exports a mailing list in RDF.
 \item Buxon, a browser for SIOC Forum instances.
\end{itemize}

\begin{figure}[ht]
 \centering
 \includegraphics[bb=0 0 300 283]{images/swaml.png}
 \caption{Processes involved in SWAML}
\end{figure}

Each one fulfils a concrete purpose into the global goals that the 
project desires to achieve. The project covers both the data exporation 
phase and the data consumption phase.

\subsection{SWAML}

The main component, the core, that has the same name than the project. 
SWAML is the tool in charge to process the mailing lists. SWAML reads a 
collection of email messages stored in a mailbox and generates a RDF 
description. It is written in Python using SIOC as the main ontology to 
represent a mailing list in RDF.

\begin{figure}[ht]
 \centering
 \includegraphics[bb=0 0 238 200]{images/swaml-process.png}
 \caption{SWAML core process}
\end{figure}

Basically it parses a mailing list, a non trivial task, compatible with 
RFC 4155~\cite{RFC4155} and it serializes it to RDF as a Forum according 
to the SIOC ontology. Parsing a mailing list it is a complex task 
because a mailbox is a structured data file based on non unique identifiers.
Each message includes a field (\textsf{Message-ID}) arbitrarily assigned by 
the SMTP server used. This field is used by mail clients to answer a message
linking it using another field (\textsf{In-Reply-To}) in the reply messages. 
Then the tool must be able to recompose the conversation threads using this 
non unique ids, trying to resolve the possible conflicts found using several 
heuristic algorithms. %(FIXME: this paragraph is not clear, rewrite it)

Not only does this component export a mailbox, but it also goes a little 
further...

Firstly it tries to find a FOAF profile that describes a person with the 
mail address of each subscriber. This is not easy taking into account 
infrastructure of the current Semantic Web, since there is no service 
that provides this specific functionality. For the moment this module is 
only a mock, but it will fully work as soon as we finish another related 
project

Secondly it exports all the geographical information found in these FOAF 
profiles into KML~\cite{Ricket2006}, to draw the point into Google Maps or 
Google Earth.

\begin{figure}[ht]
 \centering
 \includegraphics[bb=0 0 400 285]{images/googlemaps.png}
 \caption{Subscribers' geographical information on Google Maps}
\end{figure}

\subsection{Buxon}

Buxon is the application written in PyGTK that makes the opposite work. It 
takes the URI of a generic SIOC Forum (for example a mailing list exported 
by SWAML, although it is independent of the export tool) and it recomposes 
the graph. With that graph the tool displays the posts ordered by threads using 
a similar GUI to that of a classic mail client.

\begin{figure}[ht]
 \centering
 \includegraphics[bb=0 0 288 202]{images/buxon.png}
 \caption{Buxon in action (FIXME: add a screenshot of v0.0.4)}
\end{figure}

In addition it allows making simple searches by terms and dates, using
SPARQL queries over the backend graph.

In addition the latest versions of Buxon have support for 
PingTheSemanticWeb.com\footnote{\url{http://pingthesemanticweb.com/}}, 
a social web service where people can send a ping each time they find 
a Semantic Web document. If the user wants, Buxon will warn to 
PingTheSemanticWeb.com what's the URIs of the SIOC documents browsed,
contributing to create an infrastructure letting people easily create, 
find and publish RDF documents.

\section{\label{sec:conclusions}Conclusions and Future Work}

There is a lot of ongoing effort to translate data already reachable
on the web into formats which are Semantic Web-friendly. Most of that 
work focuses on relational databases, microformats and web services. 
However, at the time of this writing and to the best of our knowledge, 
e-mail was almost excluded from the Semantic Web. This project, in 
combination with the generic SIOC framework, fills this gap, conveniently 
providing an ontology and a parser to publish machine-readable versions 
of the archives of the countless mailing lists.

The SWAML project fulfills a much-needed requirement for the Semantic Web: 
to be able to refer to semantic versions of email messages and their 
properties using a resource URI. By reusing the SIOC vocabulary for describing
online discussions, SWAML allows users of SIOC to refer to email messages 
from other discussions taking place on forums, blogs, etc., so that distributed 
conversations can occur across these discussion media. Also, by providing email 
messages in SIOC format, SWAML are providing a rich source of data, namely 
mailing lists, for use in SIOC applications.

Some benefits arouse from the availability of these data. In the first
place, data can be fetched by user applications to provide handy browsing
through the archives of the mailing lists, providing features that
exceed what is now offered by static HTML versions of the archives on
the web.

Secondly, the bot crawlers of the web search engines can use the enhanced
expressivity of the RDF data to refine search results. For instance, it
becomes possible to filter out repeated messages, advance in the fight against
spam, or introduce additional filter criteria in the search forms.

Another consequence of no lesser importance is that each e-mail message
is assigned a URI that can be resolved to a machine-readable description
of the message. This actually makes possible to link a message like
any other web resource, and therefore enriches the expressivity of the
web.

We are exploring some directions for future work. Some of them are:

\begin{itemize}
  \item Integration of the SWAML process with a popular HTML-based
        mailing list archiver, such as Hypermail or Pipermail, would be
        a gigant push to speed up the adoption of SWAML. It is well
        known that one of the most awkward problems of any technology
        is to gain a critical mass of users. The semantic web is not
        an exception. A good recipe to tackle this problem is to
        integrate the new technologies into old tools, making
        a smooth transition without requiring any extra effort from
        the users. Merging the SWAML process into the batch flow of
        tools such as Hypermail would allow to generate both
        HTML and RDF versions of the archive. Those could reside
        side-by-side on the web server, even sharing the same URI
        by means of content-negotiation~\cite{Recipes}.
  \item Actually, integration could be pushed further away through
        RDFa~\cite{Birbeck2006}, embedding the RDF content into the
        XHTML documents.
  \item So far, no semantic annotation relative to the meaning of
        the messages is considered. Obviously, this information can not
        be derived from a RFC 4155-compilant mailbox.
        However, it is
        conceivable that it can be added by other means, for instance,
        by social tagging using folksonomies, or by parsing the RDFa
        that can exist in the messages that are send in XHTML format.
  \item The metadata extracted from a mailing list archive can be
        quite huge. Even after removing the body of the messages, the
        XML/RDF metadata of a mailing list containing 1000 messages may
        have a size of 4 MBytes, with a linear growth. It is not uncommon
        for a busy mailing list to generate this volume of messages
        monthly. Hence, it is imperative to design a mechanism to
        fragmentate the dataset. The SWAML process splits each message
        in a separate RDF document, but this arbitrary decision clearly
        does not fit every application. A much better solution would be to
        create an easy-to-deploy SPARQL endpoint~\cite{SPARQLProtocol},
        that translates the
        decision on how to partition the data to the final application.
  \item It is not always possible to obtain a mailbox file for a mailing
        list. For these cases, an alternative is envisaged: a high-capacity
        GMail account can be subscribed to the mailing list with the unique
        purpose of collecting and storing the messages. A simple extension
        to SWAML that makes possible to import the contents of a GMail
        account has been developed.

\end{itemize}

\section*{Acknowledgements}

The authors would like to express their gratitude to Dr. John Breslin and
Uldis Bojars from DERI Galway, whose support and contributions have been of 
great help to this project.

\bibliographystyle{abbrv}
\bibliography{../references}
%
\end{document}
